{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d743d-d0ff-4400-8a6e-1f92b19651b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237b577-9e63-4db2-b517-03e6232f3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = 'Fruits_Vegetables/train'\n",
    "data_test_path = 'Fruits_Vegetables/test'\n",
    "data_val_path = 'Fruits_Vegetables/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757afa4-c1a9-4eba-9dd0-1aa3eb05b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 180\n",
    "img_height =180 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80333e90-0e08-4921-ace3-cdb58267d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_train_path,\n",
    "    shuffle=True,\n",
    "    image_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    validation_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f9d7b-9ac8-47a4-9772-ef398c72b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e1e80-9d90-4ce5-b758-434ca9e88666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save class names to a text file\n",
    "with open('class_names.txt', 'w') as f:\n",
    "    for class_name in data_cat:\n",
    "        f.write(class_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806f7b3-768b-40a2-8ae4-5a829ee7b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(data_val_path,\n",
    "                                                       image_size=(img_height,img_width),\n",
    "                                                       batch_size=32,\n",
    "                                                        shuffle=False,\n",
    "                                                       validation_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642a2a2-f0e3-402e-8c51-4126609f3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "data_test_path,\n",
    "    image_size=(img_height,img_width),\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52864b42-f001-4309-8983-830a26ce48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for image, labels in data_train.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(image[i].numpy().astype('uint8'))\n",
    "        plt.title(data_cat[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04224164-109a-44b9-88d1-a6d453bbb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a992c23-c6ec-44cd-8c3f-bc2bd8ed51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fe18b-bcd9-473c-a538-622cc59236b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32,3, padding='same',activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128),\n",
    "    layers.Dense(len(data_cat))\n",
    "                  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9b675-7a68-4474-b76d-f0bae882dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af04e1b-89f9-43cf-b4e4-46a03a5e1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_size = 25\n",
    "history = model.fit(data_train, validation_data=data_val, epochs=epochs_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34520a4-8a46-4c32-a7ca-d23ccab7baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs_size)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range,history.history['accuracy'],label = 'Training Accuracy')\n",
    "plt.plot(epochs_range, history.history['val_accuracy'],label = 'Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range,history.history['loss'],label = 'Training Loss')\n",
    "plt.plot(epochs_range, history.history['val_loss'],label = 'Validation Loss')\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32079289-3b3a-4329-8d47-3f32bba603cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'corn.jpg'\n",
    "image = tf.keras.utils.load_img(image, target_size=(img_height,img_width))\n",
    "img_arr = tf.keras.utils.array_to_img(image)\n",
    "img_bat=tf.expand_dims(img_arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e303d-7fa6-46c1-a525-db13590bb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(img_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2491d5-87b0-4904-85d5-cf59a0078324",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.nn.softmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95af83-a97d-4aa2-8584-fc6d89261ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Veg/Fruit in image is {} with accuracy of {:0.2f}'.format(data_cat[np.argmax(score)],np.max(score)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d76b4-7666-4752-98b6-060b9a2bc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/Ragib/Desktop/Temp_arif/Image_classify.h5') # change according to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7cf31-1fe3-4b9c-a2ce-0a9fe2749f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries needed for analysis\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to analyze the image dataset\n",
    "def analyze_image_dataset(base_dir, class_names):\n",
    "    results = []\n",
    "    \n",
    "    # Analyze each class\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        files = os.listdir(class_path)\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        file_sizes = []\n",
    "        resolutions = []\n",
    "        \n",
    "        # Analyze each image\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            # Get file size in KB\n",
    "            file_size = os.path.getsize(img_path) / 1024  # KB\n",
    "            file_sizes.append(file_size)\n",
    "            \n",
    "            # Get image resolution\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "                resolutions.append((width, height))\n",
    "        \n",
    "        # Compile results\n",
    "        result = {\n",
    "            'class_name': class_name,\n",
    "            'num_files': len(image_files),\n",
    "            'file_size_min_kb': round(min(file_sizes), 2) if file_sizes else 0,\n",
    "            'file_size_max_kb': round(max(file_sizes), 2) if file_sizes else 0,\n",
    "            'file_size_avg_kb': round(np.mean(file_sizes), 2) if file_sizes else 0,\n",
    "            'min_resolution': min(resolutions, key=lambda x: x[0]*x[1]) if resolutions else (0, 0),\n",
    "            'max_resolution': max(resolutions, key=lambda x: x[0]*x[1]) if resolutions else (0, 0),\n",
    "            'sample_files': image_files[:3] if len(image_files) > 3 else image_files\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze all three datasets\n",
    "datasets = {\n",
    "    'train': data_train_path,\n",
    "    'validation': data_val_path,\n",
    "    'test': data_test_path\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "# Run analysis for each dataset\n",
    "for dataset_name, dataset_path in datasets.items():\n",
    "    print(f\"Analyzing {dataset_name} dataset...\")\n",
    "    results = analyze_image_dataset(dataset_path, data_cat)\n",
    "    all_results[dataset_name] = results\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    df = pd.DataFrame(results)\n",
    "    df['min_resolution_str'] = df['min_resolution'].apply(lambda x: f\"{x[0]}x{x[1]}\")\n",
    "    df['max_resolution_str'] = df['max_resolution'].apply(lambda x: f\"{x[0]}x{x[1]}\")\n",
    "    \n",
    "    # Display summary for this dataset\n",
    "    print(f\"\\n{dataset_name.upper()} DATASET SUMMARY:\")\n",
    "    display(df[['class_name', 'num_files', 'file_size_min_kb', \n",
    "                'file_size_max_kb', 'file_size_avg_kb', \n",
    "                'min_resolution_str', 'max_resolution_str']])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(f'{dataset_name}_dataset_analysis.csv', index=False)\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(df['class_name'], df['num_files'], color='skyblue')\n",
    "    plt.title(f'Number of Images per Class - {dataset_name.capitalize()} Dataset')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Create a comprehensive report\n",
    "with open('complete_dataset_report.txt', 'w') as f:\n",
    "    f.write(\"COMPLETE DATASET ANALYSIS REPORT\\n\")\n",
    "    f.write(\"===============================\\n\\n\")\n",
    "    \n",
    "    for dataset_name, results in all_results.items():\n",
    "        f.write(f\"{dataset_name.upper()} DATASET\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\\n\")\n",
    "        \n",
    "        for item in results:\n",
    "            f.write(f\"CLASS: {item['class_name']}\\n\")\n",
    "            f.write(f\"Number of files: {item['num_files']}\\n\")\n",
    "            f.write(f\"File size range: {item['file_size_min_kb']}KB to {item['file_size_max_kb']}KB (avg: {item['file_size_avg_kb']}KB)\\n\")\n",
    "            min_res = f\"{item['min_resolution'][0]}x{item['min_resolution'][1]}\"\n",
    "            max_res = f\"{item['max_resolution'][0]}x{item['max_resolution'][1]}\"\n",
    "            f.write(f\"Resolution range: {min_res} to {max_res}\\n\")\n",
    "            f.write(f\"Sample files: {', '.join(str(x) for x in item['sample_files'])}\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "print(f\"\\nAnalysis complete! Comprehensive results saved to CSV files and 'complete_dataset_report.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
